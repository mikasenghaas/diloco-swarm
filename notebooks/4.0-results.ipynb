{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Results\n",
    "\n",
    "This notebook analyses the results of experiments as tracked to W&B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import Dict\n",
    "\n",
    "import wandb\n",
    "from wandb.sdk.wandb_run import Run\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WANDB_ENTITY = \"mikasenghaas\"\n",
    "WANDB_PROJECT = \"swarm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def get_gpu(run: Run) -> str:\n",
    "    if \"gpu_nvidia\" in run.metadata:\n",
    "        gpu = run.metadata[\"gpu_nvidia\"][0]\n",
    "        return {\"name\": gpu[\"name\"], \"memory\": gpu[\"memoryTotal\"], \"count\": len(run.metadata[\"gpu_nvidia\"])}\n",
    "    elif \"gpuapple\" in run.metadata:\n",
    "        return {\"name\": run.metadata[\"gpuapple\"][\"gpuType\"], \"count\": 1}\n",
    "    else:\n",
    "        return {\"name\": \"Unknown\"}\n",
    "\n",
    "def get_config(run: Run) -> Dict:\n",
    "    return {**run.config, \"gpu\": get_gpu(run)}\n",
    "\n",
    "def get_history(run: Run) -> pd.DataFrame:\n",
    "    run_id = run.id\n",
    "    history = run.history()\n",
    "    return pd.concat([pd.Series([run_id]*len(history), name=\"run_id\"), history], axis=1).set_index(\"run_id\")\n",
    "\n",
    "def get_summary(run: Run) -> pd.Series:\n",
    "    return pd.DataFrame([dict(run.summary)], index=[run.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styling\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"Blues_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B\n",
    "api = wandb.Api()\n",
    "\n",
    "# Get runs\n",
    "ALL_RUNS = api.runs(f\"{WANDB_ENTITY}/{WANDB_PROJECT}\")\n",
    "print(f\"âœ… Loaded {len(ALL_RUNS)} runs from W&B ({WANDB_ENTITY}/{WANDB_PROJECT})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Verify Gradient Accumulation\n",
    "\n",
    "This experiment verifies that gradient accumulation works as expected. We do so by training a model based on the debug configuration with different micro-batch sizes and the same global batch size locally (Apple M1).\n",
    "\n",
    "View the experiment: [W&B](https://wandb.ai/mikasenghaas/swarm/workspace?nw=dm6rh6z8t14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load runs\n",
    "GROUP = \"verify/grad-acc\"\n",
    "RUNS = [r for r in ALL_RUNS if r.group == GROUP]\n",
    "\n",
    "print(f\"âœ… Loaded {len(RUNS)} runs for experiment {GROUP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config, summary, history\n",
    "runs_config = {r.id: get_config(r) for r in RUNS}\n",
    "runs_summary = pd.concat([get_summary(r) for r in RUNS])\n",
    "runs_history = pd.concat([get_history(r) for r in RUNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss by step\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(16, 4), dpi=300)\n",
    "sns.lineplot(data=runs_history, x=\"_step\", y=\"train/loss/current\", hue=\"run_id\", marker=\"o\", ax=ax[0])\n",
    "sns.lineplot(data=runs_history, x=\"_step\", y=\"train/loss/average\", hue=\"run_id\", marker=\"o\", ax=ax[1])\n",
    "ax[0].set_title(\"Loss by Step\")\n",
    "ax[1].set_title(\"Loss by Step (Average)\")\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Step\")\n",
    "    a.set_ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, gradient accumulation works. For every step, we are accumulating gradients over various micro-batches, and the we perform the same gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Wall-Time by Run\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(16, 4), dpi=300)\n",
    "sns.barplot(data=runs_summary, x=runs_summary.index, y=\"_runtime\", ax=ax[0])\n",
    "sns.barplot(data=runs_summary, x=runs_summary.index, y=\"train/throughput/average\", ax=ax[1])\n",
    "ax[0].set_title(\"Wall-Time by Run\")\n",
    "ax[1].set_title(\"Throughput by Run\")\n",
    "ax[0].set_ylabel(\"Wall-Time (s)\")\n",
    "ax[1].set_ylabel(\"Throughput (T/s)\")\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Micro-Batch Size\")\n",
    "    a.set_xticks(range(len(runs_summary)))\n",
    "    a.set_xticklabels([runs_config[run_id]['train']['micro_batch_size'] for run_id in runs_summary.index]);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the wall-time decreases with increasing micro-batch size, as expected. This is, because we are processing more tokens per second (using GPU hardware more efficiently)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Cosine LR Scheduler\n",
    "\n",
    "This experiment verifies that the cosine learning rate scheduling works as expected, e.g. the learning rate is 0 at the start, then linearly increases for `train.scheduler.warmup_steps`, after which the cosine schedule kicks in and the learning rate decays according to a cosine annealing pattern until it reaches a minimum learning rate of `train.scheduler.min_lr_factor` of the initial learning rate. The experiment is run with the debug configuration from the script `experiments/verify/scheduler.sh` and run locally on an Apple M1.\n",
    "\n",
    "View the experiment: [W&B](https://wandb.ai/mikasenghaas/swarm/workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load runs\n",
    "GROUP = \"verify/scheduler\"\n",
    "RUNS = [r for r in ALL_RUNS if r.group == GROUP]\n",
    "\n",
    "print(f\"âœ… Loaded {len(RUNS)} runs for experiment {GROUP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config, summary, history\n",
    "runs_config = {r.id: get_config(r) for r in RUNS}\n",
    "runs_summary = pd.concat([get_summary(r) for r in RUNS])\n",
    "runs_history = pd.concat([get_history(r) for r in RUNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate patterns\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=300)\n",
    "sns.lineplot(data=runs_history, x=\"_step\", y=\"train/learning_rate/current\", hue=\"run_id\", ax=ax)\n",
    "ax.set_title(\"Learning Rate by Step (All Runs)\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Learning Rate\")\n",
    "plt.legend(title=\"Run ID\")\n",
    "\n",
    "# Create custom legend with scheduler configuration\n",
    "run_ids = runs_config.keys()\n",
    "enable = [runs_config[run_id]['train']['scheduler']['enable'] for run_id in run_ids]\n",
    "warmup_steps = [runs_config[run_id]['train']['scheduler']['warmup_steps'] for run_id in run_ids]\n",
    "min_lr_factor = [runs_config[run_id]['train']['scheduler']['min_lr_factor'] for run_id in run_ids]\n",
    "\n",
    "legend_elements = []\n",
    "for run_id, e, w, m in zip(run_ids, enable, warmup_steps, min_lr_factor):\n",
    "    color = ax.get_lines()[list(run_ids).index(run_id)].get_color()\n",
    "    legend_elements.append(plt.Line2D([0], [0], color=color, lw=2, label=f\"{run_id} (enable={e}, warmup_steps={w}, min_lr_factor={m})\"))\n",
    "\n",
    "ax.legend(handles=legend_elements, title=\"Scheduler Config\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, looks good. The hyperparameter affect the learning rate pattern as expected:\n",
    "\n",
    "- `enable`: The learning rate is constant at the initial learning rate for `False` and otherwise follows a cosine annealing pattern.\n",
    "- `warmup_steps`: The learning rate is linearly increased from the initial learning rate to the maximum learning rate over `warmup_steps` steps.\n",
    "- `min_lr_factor`: The learning rate is multiplied by `min_lr_factor` at the end of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "In this experiment, we are benchmarking the throughput of various GPUs on the [Prime Intellect Compute](https://api.primeintellect.ai) platform. Namely, we are comparing the following GPUs:\n",
    "\n",
    "- NVIDIA RTX 4090 (24GB)\n",
    "- NVIDIA A100 (40GB)\n",
    "- NVIDIA A100 (80GB)\n",
    "- *NVIDIA H100 (80GB) (not yet)*\n",
    "\n",
    "We are using the script `experiments/benchmark/{method}/{model}.sh` to run the experiment. It uses the configuration from `configs/benchmark.toml` and runs the training script for the respective method. It trains the GPT-2 (124M) for five steps on WikiText 2 (17.8M tokens). We do not use learning rate scheduling and test for various micro batch sizes, starting from 1 up to 128 (or when reaching OOM) and different precision settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline GPT-2 (124M)\n",
    "\n",
    "This experiment benchmarks the throughput when training GPT-2 (124M) for the single GPU setup with different precision settings and micro batch sizes.\n",
    "\n",
    "View the experiment: [W&B](https://wandb.ai/mikasenghaas/swarm/workspace?nw=8h2bmt4h0n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load runs\n",
    "GROUP = \"benchmark/baseline/gpt2\"\n",
    "RUNS = [r for r in ALL_RUNS if r.group == GROUP and r.state == \"finished\"]\n",
    "\n",
    "print(f\"âœ… Loaded {len(RUNS)} runs for experiment {GROUP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get config, summary, history\n",
    "runs_config = {r.id: get_config(r) for r in RUNS}\n",
    "runs_summary = pd.concat([get_summary(r) for r in RUNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct performance dataframe\n",
    "performance = runs_summary.copy()\n",
    "cost_per_hour = {\"NVIDIA A100 80GB PCIe\": 1.35, \"NVIDIA A100-SXM4-40GB\": 1.29, \"NVIDIA GeForce RTX 4090\": 0.69}\n",
    "\n",
    "# Add GPU type to summary and history\n",
    "performance[\"gpu\"] = runs_summary.index.map(lambda x: runs_config[x][\"gpu\"][\"name\"])\n",
    "performance[\"cost\"] = performance.gpu.map(lambda x: cost_per_hour[x]) * performance._runtime / 3600\n",
    "\n",
    "# Add varying constants\n",
    "performance[\"micro_batch_size\"] = runs_summary.index.map(lambda x: str(runs_config[x][\"train\"][\"micro_batch_size\"]))\n",
    "performance[\"precision\"] = runs_summary.index.map(lambda x: runs_config[x][\"train\"][\"amp\"][\"precision\"])\n",
    "performance[\"dtype\"] = runs_summary.index.map(lambda x: runs_config[x][\"train\"][\"amp\"][\"dtype\"])\n",
    "\n",
    "# Choose relevant columns\n",
    "cols = [\"gpu\", \"micro_batch_size\", \"precision\", \"dtype\", \"train/throughput/current\", \"cost\"]\n",
    "performance = performance[cols]\n",
    "\n",
    "performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the the average throughput per precision and dtype\n",
    "gpus = performance[\"gpu\"].unique()\n",
    "fig, ax = plt.subplots(ncols=len(gpus), figsize=(16, 4), dpi=300)\n",
    "fig.suptitle(\"Average Throughput per Precision and Autocast\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot 1: Throughput per Autocast and Precision\n",
    "for i, gpu in enumerate(gpus):\n",
    "    stats = performance.groupby([\"precision\", \"dtype\"])[\"train/throughput/current\"].mean()\n",
    "    precision_order = performance.groupby(\"precision\")[\"train/throughput/current\"].mean().sort_values(ascending=True).index\n",
    "    dtype_order = performance.groupby(\"dtype\")[\"train/throughput/current\"].mean().sort_values(ascending=True).index\n",
    "    colors = sns.color_palette(\"Blues\", n_colors=2)\n",
    "    sns.barplot(data=performance[performance[\"gpu\"] == gpu], x=\"dtype\", y=\"train/throughput/current\", hue=\"precision\", order=dtype_order, hue_order=precision_order, ax=ax[i], gap=0.2, palette=colors)\n",
    "    ax[i].set_title(f\"{gpu}\")\n",
    "    ax[i].set_xlabel(\"Autocast\")\n",
    "    ax[i].set_ylabel(\"Average Throughput (kT/s)\")\n",
    "    ax[i].yaxis.set_major_formatter(lambda x, p: f'{x/1000:.0f}')\n",
    "    ax[i].legend(title=\"Precision\")\n",
    "\n",
    "performance.groupby([\"gpu\", \"precision\", \"dtype\"])[\"train/throughput/current\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average throughput per micro-batch size and GPU\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(16, 8), dpi=300)\n",
    "fig.suptitle(\"Average Throughput per GPU and Micro-Batch Size\")\n",
    "stats = performance.groupby([\"gpu\", \"micro_batch_size\"])[\"train/throughput/current\"].mean()\n",
    "\n",
    "gpu_order = performance.gpu.unique()\n",
    "batch_size_order = [str(2**i) for i in range(6)]\n",
    "colors = sns.color_palette(\"Blues\", n_colors=len(batch_size_order))\n",
    "sns.barplot(data=performance, x=\"gpu\", y=\"train/throughput/current\", hue=\"micro_batch_size\", order=gpu_order, hue_order=batch_size_order, ax=ax[0], gap=0.2, palette=colors)\n",
    "ax[0].set_xlabel(\"GPU\")\n",
    "ax[0].set_ylabel(\"Average Throughput (kT/s)\")\n",
    "ax[0].yaxis.set_major_formatter(lambda x, p: f'{x/1000:.0f}')\n",
    "ax[0].legend(title=\"Micro-Batch Size\")\n",
    "\n",
    "colors = sns.color_palette(\"Blues\", n_colors=len(gpus))\n",
    "sns.barplot(data=performance, x=\"micro_batch_size\", y=\"train/throughput/current\", hue=\"gpu\", order=batch_size_order, hue_order=gpu_order, ax=ax[1], gap=0.2, palette=colors)\n",
    "ax[1].set_xlabel(\"Micro-Batch Size\")\n",
    "ax[1].set_ylabel(\"Average Throughput (kT/s)\")\n",
    "ax[1].yaxis.set_major_formatter(lambda x, p: f'{x/1000:.0f}')\n",
    "ax[1].legend(title=\"GPU\");\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best configuration per GPU\n",
    "peak_performance = performance.groupby(\"gpu\").apply(lambda x: x.loc[x[\"train/throughput/current\"].idxmax()], include_groups=False)\n",
    "\n",
    "baseline = peak_performance.loc[peak_performance.cost.idxmin()]\n",
    "peak_performance[\"cost_factor\"] = peak_performance.cost / baseline.cost\n",
    "peak_performance[\"throughput_factor\"] = peak_performance[\"train/throughput/current\"] / baseline[\"train/throughput/current\"]\n",
    "\n",
    "peak_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for this training run, the GeForce RTX 4090 is the best cost-to-performance choice. Compared to the A100 40GB, we are paying 1.66x times the price for ~7% throughput improvement, and for the A100 80GB wwe are paying 1.59x the price for ~13% improvement. As long as we are not training distributed, the 4090 is a very good choice. We should choosen `micro_batch_size=4` and train on half precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
